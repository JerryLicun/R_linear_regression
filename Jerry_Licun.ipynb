{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MlGsu74PRze0"
   },
   "source": [
    "[<h1> FIT5197 Assignment 3 Semester 2, 2020 </h1>](https://lms.monash.edu/mod/assign/view.php?id=7560449)\n",
    "\n",
    "---\n",
    "Authors: Dan Nguyen, Yun Zhao\n",
    "\n",
    "Admins (Competition): Dr. Levin Kuhlmann, Yun Zhao, Anil Gurbuz\n",
    "\n",
    "Proofreaders: Dr. Levin Kuhlmann, Yun Zhao, and other tutors \n",
    "\n",
    "Date: Oct 2020\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<h1> Assignment Instruction </h1>](https://lms.monash.edu/mod/assign/view.php?id=7560449)\n",
    "\n",
    "<span style=\"color:red\"> Please read through the instructions carefully, by submitting the assignment, you are considered to have read all the instructions carefully and be aware of the penalties that entail. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E-lggSuURze1"
   },
   "source": [
    "<h1>Part 1: Regression (50 Marks)</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ar--DpysOWJd"
   },
   "source": [
    "This part is about regression. Specifically, you will be ``predicting the fuel efficiency`` of a car (in kilometers per litre) based on its characteristics. This is a practical problem as Australia is one of the largest automobile markets in the world; thus, correctly predicting the fuel efficiency is necessary to control emission rates to the environment.\n",
    "\n",
    "The dataset has many observations and predictors obtained from many retailers for car models available for sale from 2017 to 2020. The target variable is the fuel efficiency of the car measured in kilometers per litre. The higher this value, the better the fuel efficiency of the car. \n",
    "\n",
    "PleaseProvide working/R code/justifications for each of these questions as required.\n",
    "\n",
    "$\\textbf{Note:}$ If not explicitly mentioned, libraries are not allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from students' side\n",
    "remove(list = ls())\n",
    "train <- read.csv(\"RegressionTrain.csv\")\n",
    "test <- read.csv(\"RegressionTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE DO NOT ALTER THIS CODE BLOCK\n",
    "# Please skip (don't run) this if you are a student\n",
    "# Read in the data from marking tutors' side (ensure no cheating!)\n",
    "remove(list = ls())\n",
    "train <- read.csv(\"../data/RegressionTrain.csv\")\n",
    "test <- read.csv(\"../data/RegressionTest.csv\")\n",
    "label <- read.csv(\"../data/RegressionTestLabel.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0epC4XmxOWJe"
   },
   "source": [
    "<h2> Question 1 (5 Marks) </h2>\n",
    "\n",
    "Fit a $\\textbf{multiple linear model}$ to the fuel efficiency data using the ``train`` dataset. By checking the summary information, which predictors/variables do you think are possibly associated with fuel efficiency (use ``0.05`` significant level), and why? Which ``three predictors/variables`` appear to be the strongest predictors of fuel efficiency, and why? \n",
    "\n",
    "$\\textbf{Note}$: You don't have to worry about categorical variables here since R can deal with this automatically, focus your efforts on interpretation. Additionally, when explaining why features are strongly associated with the target, please refrain giving one or two sentences answers, these answers are not descriptive enough and will result in deduction of marks. Finally, please name the model here ``lm.fit`` for future marking purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Ybm3VKDOWJe"
   },
   "source": [
    "$\\textbf{YOUR ANSWER HERE}$  \n",
    "When we use the summary information, we find that Model.Year, Eng.Displacement, No.Cylinders, Aspiration-SCï¼Œ Aspiration-TC, Aspiration-TS, No.Gears, Lockup.Torque.Converter-Y, Drive.Sys-F, Fuel.Type-GP, and Max.Ethanol are possibly associated with fuel efficiency because from the summary result, we know that they satisfied the 0.05 significant level.  \n",
    "Then, we find that the values with the smallest significant level are Aspiration-SC, Aspiration-TC, Lockup.Torque.Converter-Y, Drive.Sys-F, Eng.Displacement, No.Cylinders, and No.Gears ( *** in summary result, means the significant level approximate to 0).   \n",
    "Moreover, we find that Eng.Displacement, No.Cylinders, and No.Gears variables are continuous variables and seem to be (normal-ish) distributed. Also, fuel efficiency values also look like normal distribution.  \n",
    "In summary, we can make a conclusion that Eng.Displacement, No.Cylinders, and No.Gears variables appear to be the strongest predictors of fuel efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = Comb.FE ~ ., data = train)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-4.0256 -0.9978 -0.0644  0.7006 11.3941 \n",
       "\n",
       "Coefficients:\n",
       "                           Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)              -1.783e+02  8.587e+01  -2.076  0.03809 *  \n",
       "Model.Year                9.640e-02  4.255e-02   2.266  0.02363 *  \n",
       "Eng.Displacement         -1.364e+00  1.025e-01 -13.306  < 2e-16 ***\n",
       "No.Cylinders              4.644e-02  6.769e-02   0.686  0.49282    \n",
       "AspirationOT             -3.452e-01  6.352e-01  -0.543  0.58693    \n",
       "AspirationSC             -9.197e-01  2.282e-01  -4.031 5.85e-05 ***\n",
       "AspirationTC             -1.303e+00  1.288e-01 -10.111  < 2e-16 ***\n",
       "AspirationTS             -1.149e+00  4.945e-01  -2.323  0.02035 *  \n",
       "No.Gears                 -1.307e-01  2.995e-02  -4.364 1.37e-05 ***\n",
       "Lockup.Torque.ConverterY -8.243e-01  1.117e-01  -7.377 2.78e-13 ***\n",
       "Drive.SysA               -8.339e-02  1.521e-01  -0.548  0.58356    \n",
       "Drive.SysF                1.441e+00  1.711e-01   8.419  < 2e-16 ***\n",
       "Drive.SysP               -2.400e-01  2.980e-01  -0.805  0.42087    \n",
       "Drive.SysR                4.328e-02  1.476e-01   0.293  0.76938    \n",
       "Max.Ethanol              -7.076e-03  2.967e-03  -2.385  0.01722 *  \n",
       "Fuel.TypeGM               5.706e-01  4.173e-01   1.368  0.17169    \n",
       "Fuel.TypeGP               4.093e-01  1.369e-01   2.990  0.00284 ** \n",
       "Fuel.TypeGPR              1.363e-01  1.401e-01   0.973  0.33096    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 1.598 on 1382 degrees of freedom\n",
       "Multiple R-squared:  0.6628,\tAdjusted R-squared:  0.6586 \n",
       "F-statistic: 159.8 on 17 and 1382 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Change this\n",
    "lm.fit <-  lm(Comb.FE ~ ., train)\n",
    "summary(lm.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kEUu5eFpOWJi"
   },
   "source": [
    "<h2> Question 2 (5 Marks) </h2>\n",
    "\n",
    "Describe/discuss the effect that the year of manufacture ``(Model.Year)`` variable appears to have on the mean ``fuel efficiency``. Additionally, describe/discuss the effect that the number of gears ``(No.Gears)`` variable has on the mean ``fuel efficiency`` of the car.\n",
    "\n",
    "$\\textbf{Note}$: This asks for your descriptions, please refrain from using one or two lines to describe/discuss the effect. Keep answers to be 4 decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"In the year of  2017 , the mean of fuel efficiency is 10.3663\"\n",
      "[1] \"In the year of  2018 , the mean of fuel efficiency is 10.5806\"\n",
      "[1] \"In the year of  2019 , the mean of fuel efficiency is 10.3784\"\n",
      "[1] \"In the year of  2020 , the mean of fuel efficiency is 10.4758\"\n",
      "[1] \"-----------------------------------------------------------------------------\"\n",
      "[1] \"When the number of gears is 3 , the mean of fuel efficiency is 13.7678\"\n",
      "[1] \"When the number of gears is 4 , the mean of fuel efficiency is 12.465\"\n",
      "[1] \"When the number of gears is 5 , the mean of fuel efficiency is 9.9472\"\n",
      "[1] \"When the number of gears is 6 , the mean of fuel efficiency is 9.5233\"\n",
      "[1] \"When the number of gears is 8 , the mean of fuel efficiency is 7.8253\"\n",
      "[1] \"When the number of gears is 10 , the mean of fuel efficiency is 7.1439\"\n",
      "[1] \"When the number of gears is 12 , the mean of fuel efficiency is 6.6503\"\n",
      "[1] \"When the number of gears is 16 , the mean of fuel efficiency is 4.9736\"\n"
     ]
    }
   ],
   "source": [
    "for (i in sort(unique(train$Model.Year))){\n",
    "mean_value = round(mean(train$Comb.FE[which(train$Model.Year == i)] ),4)\n",
    "print(paste(\"In the year of \", i ,\", the mean of fuel efficiency is\", mean_value))\n",
    "    }\n",
    "print(\"-----------------------------------------------------------------------------\")\n",
    "for (i in sort(unique(train$No.Cylinders))){\n",
    "mean_value = round(mean(train$Comb.FE[which(train$No.Cylinders == i)] ),4)\n",
    "print(paste(\"When the number of gears is\", i ,\", the mean of fuel efficiency is\", mean_value))\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Ybm3VKDOWJe"
   },
   "source": [
    "$\\textbf{YOUR ANSWER HERE}$  \n",
    "In the different years of manufacture, the mean of fuel efficiency looks similar, the values range of it is from 10.3663 to 10.5806. So, we think that the year of manufacture has a slight impact on the mean fuel efficiency.  \n",
    "On the other hand, the number of gears has a significant effect on the mean fuel efficiency.   \n",
    "To be specific, the higher number of gears, the lower number of the mean fuel efficiency. When the number of gears is 3, we record the highest fuel efficiency, which is 13.7678. However, when the number of gears is 16, the mean fuel efficiency reaches the lowest point, which is 4.9736.  \n",
    "On the other hand, from the linear model, we know that the mean fuel efficiency increase by 0.0964 per year, and with each additional number of gears, the mean fuel efficiency drops 0.1307.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C6XyKtwfOWJj"
   },
   "source": [
    "<h2> Question 3 (5 Marks) </h2>\n",
    "\n",
    "Apply the stepwise selection procedure with the $\\textbf{BIC}$ penalty to prune out potentially less significant variables. Write down the final regression equation obtained after pruning, please keep the values of the parameter coefficients to 2 decimal places. Finally, also describe the pruned model.\n",
    "\n",
    "$\\textbf{Note}$: please don't change the default direction ``both`` in the step function, this is so that we can check your work easily. Additionally, please name this model ``sw.fit``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{YOUR ANSWER HERE}$  \n",
    "##### Introduce to BIC:\n",
    "When training the model, increasing the number of parameters, namely increasing the complexity of the model, and will increase the precision of the likelihood function, but will also lead to the overfitting phenomenon. To solve this problem, AIC and BIC both introduced a penalty term related to the number of model parameters, and BIC's penalty term is larger than AIC. Considering the number of samples, large samples can effectively prevent the model complexity caused by too high precision.  \n",
    "The smaller the BIC values, the better the regression equation it is.\n",
    "##### The final regression equation is:\n",
    "$ Comb.FE = 16.20 -1.28 \\times Eng.Displacement - 0.10 \\times AspirationOT -0.70 \\times AspirationSC - 1.14 \\times AspirationTC - 1.12 \\times AspirationTS -0.11 \\times No.Gears -0.82 \\times No.Gears Lockup.Torque.ConverterY + 0.03 \\times Drive.SysA + 1.48 \\times Drive.SysF -0.32 \\times Drive.SysP +  0.09 \\times Drive.SysR -  0.01 \\times Max.Ethanol $  \n",
    "##### Describe the pruned model  \n",
    "The intercept values of the pruned model is 16.20.  \n",
    "From this model, we can conclude that Drive.Sys-F has a strongly positive impact on fuel efficiency, which can increase by 1.48. Also, Drive.SysA and Drive.SysR can increase fuel efficiency slightly.   \n",
    "Other values will harm the fuel efficiency.   \n",
    "To be specific, with 1 increase in engine displacement, the fuel efficiency will decrease 1.28. Also, AspirationTC and AspirationTS will decrease fuel efficiency by 1.14 and 1.12 respectively. The remaining variables will drop fuel efficiency mildly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this\n",
    "sw.fit <- step(lm.fit, trace=0, k = log(nrow(train)), direction=\"both\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "izq8RU0lOWJn"
   },
   "source": [
    "<h2> Question 4 (5 Marks) </h2>\n",
    "\n",
    "Say we are going to buy a new car and we want to improve the fuel efficiency of our new car, what does this ``BIC model`` suggest we should do? Provide a detailed answers of at least ``150 words``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Ybm3VKDOWJe"
   },
   "source": [
    "$\\textbf{YOUR ANSWER HERE}$  \n",
    "From the BOC model, we know the coefficients of each variables in this multiple linear model. The function is :   \n",
    "Fuel.efficiency = $16.20 -1.28 \\times Eng.Displacement - 0.10 \\times AspirationOT -0.70 \\times AspirationSC - 1.14 \\times AspirationTC - 1.12 \\times AspirationTS -0.11 \\times No.Gears -0.82 \\times No.Gears Lockup.Torque.ConverterY + 0.03 \\times Drive.SysA + 1.48 \\times Drive.SysF -0.32 \\times Drive.SysP +  0.09 \\times Drive.SysR -  0.01 \\times Max.Ethanol $   \n",
    "\n",
    "From this function, in order to improve the fuel efficiency of our new car, we need to choose the lowest engine displacement, the number of cylinders and the number of gears. If these variables are the minimum, the fuel efficiency of this car is pretty high.  \n",
    "Also, choosing F as the Drive system is a good choice, which can increase 1.48 of fuel efficiency.   \n",
    "It is difficult for a car to get the minimum value of these variables at the same time, we need to make a balance between them.   \n",
    "To be specific, engine displacement is the most important variable, we need to consider the lowest engine displacement at first. After that, we will consider the number of gears and the number of cylinders, also we need to choose the Drive system F.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bhFKnrlcOWJo"
   },
   "source": [
    "<h2> Question 5 (5 Marks)</h2>\n",
    "\n",
    "Imagine that you are looking for a new car to buy to replace your existing car. Use the $\\textbf{test}$ dataset to inspect the first car fuel efficiency and see whether it is a good fit for you or not.\n",
    "    \n",
    "    (a) Use your BIC model to predict the mean fuel efficiency for this new car. Provide a 95% confidence interval for this prediction. [2 mark]\n",
    "    (b) Following the previous estimation, given that the current car that you own has a mean fuel efficiency of 9.5 km/l (measured over the life time of your ownership), does your model (BIC) suggest that the new car will have better fuel efficiency than your current car? Why? [3 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 1 Ã— 3 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>fit</th><th scope=col>lwr</th><th scope=col>upr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>9.287257</td><td>9.052956</td><td>9.521557</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 1 Ã— 3 of type dbl\n",
       "\\begin{tabular}{r|lll}\n",
       "  & fit & lwr & upr\\\\\n",
       "\\hline\n",
       "\t1 & 9.287257 & 9.052956 & 9.521557\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 1 Ã— 3 of type dbl\n",
       "\n",
       "| <!--/--> | fit | lwr | upr |\n",
       "|---|---|---|---|\n",
       "| 1 | 9.287257 | 9.052956 | 9.521557 |\n",
       "\n"
      ],
      "text/plain": [
       "  fit      lwr      upr     \n",
       "1 9.287257 9.052956 9.521557"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict(sw.fit, newdata = test[1,], interval = \"confidence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Ybm3VKDOWJe"
   },
   "source": [
    "$\\textbf{YOUR ANSWER HERE}$  \n",
    "(1) From the predict code result, we calculate a 95% confidence interval for the first car in test dataset is\n",
    "$[9.0530,9.5216]$\n",
    "\n",
    "(2)The 95% confidence interval for this prediction is $[9.0530,9.5216]$, and 9.5 km/l is near the largest value of this interval. To be specific, the possibility of this new car has better fuel efficiency is bigger than 50%, which may be 80% - 95%.   \n",
    "As a result, my model (BIC) suggest that the new car will have better fuel efficiency than my current car.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Question 6 (Libraries are allowed) (25 Marks) </h2>\n",
    "\n",
    "As a Data Scientist, one of the key tasks is to build models $\\textbf{most appropriate/closest}$ to the truth; thus, modelling will not be limitted to these steps in the assignment. To simulate for a realistic modelling process, this question will be in the form of a competition among students to find out who has the best model.\n",
    "\n",
    "Thus, You will be graded by the performance of your model compared to your classmates', the better your model, the higher your score. Additionally, you need to write a short paragraph describing/documenting your thought process in this model building process ``(300 words)``. Note that this is to explain to us why you build your current model so that we can verify that you understand the model you build and not just copy from other people.\n",
    "\n",
    "$\\textbf{Note}$ Please make sure that we can install the libraries that you use in this part, the code structure can be:\n",
    "\n",
    "``install.packages(\"some package\", repos='http://cran.us.r-project.org')``\n",
    "\n",
    "``library(\"some package\")``\n",
    "\n",
    "Remember that if we cannot run your code, we will have to give you 0 marks, our suggestion is for you to use the standard ``R version 3.6.1``\n",
    "\n",
    "You also need to name your final model ``fin.mod`` so we can run a check to find out your performance. A good test for your understanding would be to set the previous $\\textbf{BIC model}$ to be the final model to check if your code works Appropriately.\n",
    "\n",
    "$20$ Marks for the model performance in the competition\n",
    "\n",
    "$5$ Marks for logically writing down the thought process in building the final model\n",
    "\n",
    "This is the [link](https://www.kaggle.com/t/0a3c0fc91b074816a6315bb4e9b42602) to the competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{YOUR ANSWER HERE}$  \n",
    "I write a short paragraph describing/documenting my thought process in this model building process under each code block. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"When the fuel type is  G , the mean of fuel efficiency is 11.2888\"\n",
      "[1] \"When the fuel type is  GM , the mean of fuel efficiency is 8.2516\"\n",
      "[1] \"When the fuel type is  GP , the mean of fuel efficiency is 10.0892\"\n",
      "[1] \"When the fuel type is  GPR , the mean of fuel efficiency is 9.458\"\n",
      "[1] \"-----------------------------------------------------------------------------------\"\n",
      "[1] \"When the Aspiration is  N , the mean of fuel efficiency is 10.6972\"\n",
      "[1] \"When the Aspiration is  OT , the mean of fuel efficiency is 10.3347\"\n",
      "[1] \"When the Aspiration is  SC , the mean of fuel efficiency is 8.4332\"\n",
      "[1] \"When the Aspiration is  TC , the mean of fuel efficiency is 10.4079\"\n",
      "[1] \"When the Aspiration is  TS , the mean of fuel efficiency is 10.7384\"\n",
      "[1] \"-----------------------------------------------------------------------------------\"\n",
      "[1] \"When the Lockup Torque Converter is N , the mean of fuel efficiency is 11.8128\"\n",
      "[1] \"When the Lockup Torque Converter is Y , the mean of fuel efficiency is 10.0347\"\n",
      "[1] \"-----------------------------------------------------------------------------------\"\n",
      "[1] \"When the Max.Ethanol is 10 , the mean of fuel efficiency is 10.1536\"\n",
      "[1] \"When the Max.Ethanol is 15 , the mean of fuel efficiency is 11.1591\"\n",
      "[1] \"When the Max.Ethanol is 85 , the mean of fuel efficiency is 8.9424\"\n",
      "[1] \"-----------------------------------------------------------------------------------\"\n",
      "[1] \"When the drive system is  4 , the mean of fuel efficiency is 8.9557\"\n",
      "[1] \"When the drive system is  A , the mean of fuel efficiency is 9.984\"\n",
      "[1] \"When the drive system is  F , the mean of fuel efficiency is 13.0806\"\n",
      "[1] \"When the drive system is  P , the mean of fuel efficiency is 8.383\"\n",
      "[1] \"When the drive system is  R , the mean of fuel efficiency is 9.3161\"\n"
     ]
    }
   ],
   "source": [
    "# Print out the relationship between fuel effeciency and each variables\n",
    "\n",
    "# print Fuel.Type Column\n",
    "for (i in sort(unique(train$Fuel.Type))){\n",
    "mean_value = round(mean(train$Comb.FE[which(train$Fuel.Type == i)] ),4)\n",
    "print(paste(\"When the fuel type is \", i ,\", the mean of fuel efficiency is\", mean_value))\n",
    "    }\n",
    "print(\"-----------------------------------------------------------------------------------\")\n",
    "\n",
    "# print Aspiration Column\n",
    "for (i in sort(unique(train$Aspiration))){\n",
    "mean_value = round(mean(train$Comb.FE[which(train$Aspiration == i)] ),4)\n",
    "print(paste(\"When the Aspiration is \", i ,\", the mean of fuel efficiency is\", mean_value))\n",
    "    }\n",
    "print(\"-----------------------------------------------------------------------------------\")\n",
    "\n",
    "# print Lockup.Torque.Converter Column\n",
    "for (i in sort(unique(train$Lockup.Torque.Converter))){\n",
    "mean_value = round(mean(train$Comb.FE[which(train$Lockup.Torque.Converter == i)] ),4)\n",
    "print(paste(\"When the Lockup Torque Converter is\", i ,\", the mean of fuel efficiency is\", mean_value))\n",
    "    }\n",
    "print(\"-----------------------------------------------------------------------------------\")\n",
    "\n",
    "# print Max.Ethanol Column\n",
    "for (i in sort(unique(train$Max.Ethanol))){\n",
    "mean_value = round(mean(train$Comb.FE[which(train$Max.Ethanol == i)] ),4)\n",
    "print(paste(\"When the Max.Ethanol is\", i ,\", the mean of fuel efficiency is\", mean_value))\n",
    "    }\n",
    "print(\"-----------------------------------------------------------------------------------\")\n",
    "\n",
    "# print Drive.Sys Column\n",
    "for (i in sort(unique(train$Drive.Sys))){\n",
    "mean_value = round(mean(train$Comb.FE[which(train$Drive.Sys == i)] ),4)\n",
    "print(paste(\"When the drive system is \", i ,\", the mean of fuel efficiency is\", mean_value))\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, I print out the mean of the fuel efficiency of each variable, to find out the relationship between each variable and fuel efficiency.   \n",
    "This step can help us have a general knowledge of each variable, which has a positive impact on the model set.  \n",
    "For example, there are five driver systems in the data. When the driver system is F, the fuel efficiency is significantly different from other driver systems.  \n",
    "As a result, maybe we can divide the driver systems into two groups in order to create a better model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this function to check the performance of your model\n",
    "rmse <- function(pred.label, truth.label){\n",
    "    # Lower is better\n",
    "    return(sqrt(mean((pred.label - truth.label)^2)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: model\n",
    "# Print: RSS\n",
    "rss <- function(fin.mod){\n",
    "    pred.label <- predict(fin.mod, train[,-10])\n",
    "    truth.label <- train[,10]\n",
    "    print(rmse(pred.label, truth.label))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 1.59735\n"
     ]
    }
   ],
   "source": [
    "rss(sw.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I create another function named rss.   \n",
    "This function uses the model that we build as the input, call the rmse function to calculate the RSS of that model, and print out the result.  \n",
    "In this way, we can increase the code re-use to make it clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for ( a in seq(0, 10, by = 0.1)){\n",
    "#    for ( b in seq(0, 10, by = 0.1)){\n",
    "#        for ( c in seq(0, 10, by = 0.1)){\n",
    "#            for ( d in seq(0, 10, by = 0.1)){\n",
    "#    train <- read.csv(\"RegressionTrain.csv\")\n",
    "#    training <- train[1:1000,]\n",
    "#    testing <-  train[1001:1400,]\n",
    "#                \n",
    "#    training$Fuel.Type[which(training$Fuel.Type == \"G\")] = a\n",
    "#    training$Fuel.Type[which(training$Fuel.Type == \"GM\")] = b\n",
    "#    training$Fuel.Type[which(training$Fuel.Type == \"GP\")] = c\n",
    "#    training$Fuel.Type[which(training$Fuel.Type == \"GPR\")] = d\n",
    "#    training$Fuel.Type <- as.numeric(training$Fuel.Type)\n",
    "#    print(paste(a,b,c,d))\n",
    "#    testing$Fuel.Type[which(testing$Fuel.Type == \"G\")] = a\n",
    "#    testing$Fuel.Type[which(testing$Fuel.Type == \"GM\")] = b\n",
    "#    testing$Fuel.Type[which(testing$Fuel.Type == \"GP\")] = c\n",
    "#    testing$Fuel.Type[which(testing$Fuel.Type == \"GPR\")] = d\n",
    "#    testing$Fuel.Type <- as.numeric(testing$Fuel.Type)\n",
    "                \n",
    "#    l.f <- lm(formula = Comb.FE~., training)\n",
    "#    rss(l.f)\n",
    "#}}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find many characters attributes in the data, which is not convenient for us to build a model. As a result, we need to translate these character values into numeric values.  \n",
    "In this part, we use specific numeric values to present each character's values.  \n",
    "Here is a problem, which number is the best one to present a character value?   \n",
    "To solve this, I create a for loop (you can see it in comment) from 0 to 10, step is 0.1, to try the different number for each variable, and create a multiple regression model using all the data. Then, calculate the RSS of this model. We use the numeric value which makes the RSS is minimum to present the character value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use specific numeric values to present Lockup.Torque.Converter\n",
    "train$Lockup.Torque.Converter[which(train$Lockup.Torque.Converter == \"Y\")] = 1\n",
    "train$Lockup.Torque.Converter[which(train$Lockup.Torque.Converter == \"N\" )] = 2\n",
    "train$Lockup.Torque.Converter <- as.numeric(train$Lockup.Torque.Converter)\n",
    "# Use specific numeric values to present Drive.Sys\n",
    "train$Drive.Sys[which(train$Drive.Sys == \"P\")] = 0.9\n",
    "train$Drive.Sys[which(train$Drive.Sys == \"4\" )] = 3.8\n",
    "train$Drive.Sys[which(train$Drive.Sys == \"R\")] = 5.2\n",
    "train$Drive.Sys[which(train$Drive.Sys == \"A\")] = 2.9\n",
    "train$Drive.Sys[which(train$Drive.Sys == \"F\")] = 17.3\n",
    "train$Drive.Sys <- as.numeric(train$Drive.Sys)\n",
    "# Use specific numeric values to present Aspiration\n",
    "train$Aspiration[which(train$Aspiration == \"SC\")] = 3.7\n",
    "train$Aspiration[which(train$Aspiration == \"N\" )] = 0.1\n",
    "train$Aspiration[which(train$Aspiration == \"OT\")] = 1.4\n",
    "train$Aspiration[which(train$Aspiration == \"TC\")] = 4.2\n",
    "train$Aspiration[which(train$Aspiration == \"TS\")] = 4.1\n",
    "train$Aspiration <- as.numeric(train$Aspiration)\n",
    "# Use specific numeric values to present Fuel.Type\n",
    "train$Fuel.Type[which(train$Fuel.Type == \"G\")] = 0.1\n",
    "train$Fuel.Type[which(train$Fuel.Type == \"GM\")] = 0.2\n",
    "train$Fuel.Type[which(train$Fuel.Type == \"GP\")] = 40\n",
    "train$Fuel.Type[which(train$Fuel.Type == \"GPR\")] = 3\n",
    "train$Fuel.Type <- as.numeric(train$Fuel.Type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose a fancy model building method to create the model.     \n",
    "To be specific, we fit a full model with logs of all variables, squares, and cubes of all variables. Also, it includes all interactions between predictors (two predictors multiplication or division, three predictors multiplication).  \n",
    "Next step, we apply the stepwise selection procedure with the BIC penalty to prune out potentially less significant variables and get the final model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.fit <- lm(formula = Comb.FE~. + .*. + .*.*. + log(Drive.Sys)+ log(Eng.Displacement) \n",
    "             + log(Aspiration)+ log(No.Gears)+ log(Lockup.Torque.Converter)+ log(Fuel.Type)\n",
    "             +log(Model.Year) + log(Max.Ethanol) + log(No.Cylinders)+ I(Eng.Displacement^2) \n",
    "             + I(No.Gears^2)+ I(Aspiration^2) + I(Lockup.Torque.Converter^2)+ I(Drive.Sys^2) \n",
    "             + I(Fuel.Type^2)+ I(Model.Year^2) + I(Max.Ethanol^2)+ I(No.Cylinders^2)  + I(No.Gears^3)+ I(Aspiration^3) + I(Lockup.Torque.Converter^3)+ I(Drive.Sys^3) \n",
    "             + I(Fuel.Type^3)+ I(Model.Year^3) + I(Max.Ethanol^3)+ I(No.Cylinders^3)\n",
    "             + I(Drive.Sys/Eng.Displacement) + I(Drive.Sys/Aspiration) + I(Drive.Sys/No.Gears) \n",
    "             + I(Drive.Sys/Lockup.Torque.Converter) + I(Drive.Sys/Fuel.Type)          \n",
    "             + I(Drive.Sys/Model.Year) + I(Drive.Sys/Max.Ethanol) + I(Drive.Sys/No.Cylinders) \n",
    "            + I(Eng.Displacement/Drive.Sys) + I(Eng.Displacement/Aspiration) + I(Eng.Displacement/No.Gears) \n",
    "            + I(Eng.Displacement/Lockup.Torque.Converter) + I(Eng.Displacement/Fuel.Type) + I(Eng.Displacement/Model.Year)\n",
    "            + I(Eng.Displacement/Max.Ethanol) + I(Eng.Displacement/No.Cylinders)\n",
    "            + I(Aspiration/Drive.Sys) + I(Aspiration/Eng.Displacement) + I(Aspiration/No.Gears) \n",
    "            + I(Aspiration/Lockup.Torque.Converter) + I(Aspiration/Fuel.Type) + I(Aspiration/Model.Year)\n",
    "            + I(Aspiration/Max.Ethanol) + I(Aspiration/No.Cylinders)   \n",
    "            + I(No.Gears/Drive.Sys) + I(No.Gears/Eng.Displacement) + I(No.Gears/Aspiration) \n",
    "            + I(No.Gears/Lockup.Torque.Converter) + I(No.Gears/Fuel.Type) + I(No.Gears/Model.Year)\n",
    "            + I(No.Gears/Max.Ethanol) + I(No.Gears/No.Cylinders)\n",
    "            + I(Lockup.Torque.Converter/Drive.Sys) + I(Lockup.Torque.Converter/Eng.Displacement) + I(Lockup.Torque.Converter/Aspiration) \n",
    "            + I(Lockup.Torque.Converter/No.Gears) + I(Lockup.Torque.Converter/Fuel.Type) + I(Lockup.Torque.Converter/Model.Year)\n",
    "            + I(Lockup.Torque.Converter/Max.Ethanol) + I(Lockup.Torque.Converter/No.Cylinders)\n",
    "            + I(Fuel.Type/Drive.Sys) + I(Fuel.Type/Eng.Displacement) + I(Fuel.Type/Aspiration) \n",
    "            + I(Fuel.Type/Lockup.Torque.Converter) + I(Fuel.Type/Lockup.Torque.Converter) + I(Fuel.Type/Model.Year)\n",
    "            + I(Fuel.Type/Max.Ethanol) + I(Fuel.Type/No.Cylinders)\n",
    "            + I(Model.Year/Drive.Sys) + I(Model.Year/Eng.Displacement) + I(Model.Year/Aspiration) \n",
    "            + I(Model.Year/Lockup.Torque.Converter) + I(Model.Year/Lockup.Torque.Converter) + I(Model.Year/Fuel.Type)\n",
    "            + I(Model.Year/Max.Ethanol) + I(Model.Year/No.Cylinders)\n",
    "            + I(Max.Ethanol/Drive.Sys) + I(Max.Ethanol/Eng.Displacement) + I(Max.Ethanol/Aspiration) \n",
    "            + I(Max.Ethanol/Lockup.Torque.Converter) + I(Max.Ethanol/Lockup.Torque.Converter) + I(Max.Ethanol/Fuel.Type)\n",
    "            + I(Max.Ethanol/Model.Year) + I(Max.Ethanol/No.Cylinders)\n",
    "            + I(No.Cylinders/Drive.Sys) + I(No.Cylinders/Eng.Displacement) + I(No.Cylinders/Aspiration) \n",
    "            + I(No.Cylinders/Lockup.Torque.Converter) + I(No.Cylinders/Lockup.Torque.Converter) + I(No.Cylinders/Fuel.Type)\n",
    "            + I(No.Cylinders/Model.Year) + I(No.Cylinders/Max.Ethanol)\n",
    "             , data = train) \n",
    "\n",
    "# Apply the stepwise selection procedure with the BIC penalty\n",
    "back.fit = step(b.fit ,trace=0, k = log(nrow(train)), direction=\"both\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the BIC procedure, a multiple regression model was built.   \n",
    "We use this model to calculate the testing data value, and the RSS is 1.0289, which is smaller than the previous BIC model in Question 3 (RSS=1.5974). This means sw.fit model is much better than the previous one.   \n",
    "This is my final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build your final model here, use additional coding block if you need\n",
    "fin.mod <- back.fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use my model to predict the efficiency of the fuel, we need to do some preprocessing to the test data.  \n",
    "To be specific, we need to change the character's values into some specific numeric values.  \n",
    "After that, we can use my model to predict the values in the RegressionTest.csv document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data wrangling the test data, in order to use the model.\n",
    "# Use specific numeric values to present Fuel.Type\n",
    "test$Fuel.Type[which(test$Fuel.Type == \"G\")] = 0.1\n",
    "test$Fuel.Type[which(test$Fuel.Type == \"GM\")] = 0.2\n",
    "test$Fuel.Type[which(test$Fuel.Type == \"GP\")] = 40\n",
    "test$Fuel.Type[which(test$Fuel.Type == \"GPR\")] = 3\n",
    "test$Fuel.Type <- as.numeric(test$Fuel.Type)\n",
    "# Use specific numeric values to present Aspiration\n",
    "test$Aspiration[which(test$Aspiration == \"SC\")] = 3.7\n",
    "test$Aspiration[which(test$Aspiration == \"N\" )] = 0.1\n",
    "test$Aspiration[which(test$Aspiration == \"OT\")] = 1.4\n",
    "test$Aspiration[which(test$Aspiration == \"TC\")] = 4.2\n",
    "test$Aspiration[which(test$Aspiration == \"TS\")] = 4.1\n",
    "test$Aspiration <- as.numeric(test$Aspiration)\n",
    "# Use specific numeric values to present Lockup.Torque.Converter\n",
    "test$Lockup.Torque.Converter[which(test$Lockup.Torque.Converter == \"Y\")] = 1\n",
    "test$Lockup.Torque.Converter[which(test$Lockup.Torque.Converter == \"N\" )] = 2\n",
    "test$Lockup.Torque.Converter <- as.numeric(test$Lockup.Torque.Converter)\n",
    "# Use specific numeric values to present Drive.Sys\n",
    "test$Drive.Sys[which(test$Drive.Sys == \"P\")] = 0.9\n",
    "test$Drive.Sys[which(test$Drive.Sys == \"4\" )] = 3.8\n",
    "test$Drive.Sys[which(test$Drive.Sys == \"R\")] = 5.2\n",
    "test$Drive.Sys[which(test$Drive.Sys == \"A\")] = 2.9\n",
    "test$Drive.Sys[which(test$Drive.Sys == \"F\")] = 17.3\n",
    "test$Drive.Sys <- as.numeric(test$Drive.Sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in predict.lm(fin.mod, test):\n",
      "\"prediction from a rank-deficient fit may be misleading\"\n"
     ]
    }
   ],
   "source": [
    "# If you are using any packages that perform the prediction differently, please change the value of this variable\n",
    "pred.label <- predict(fin.mod, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE DO NOT ALTER THIS CODE BLOCK\n",
    "# put this label in a csv file to commit to the Leaderboard\n",
    "write.csv(data.frame(\"RowIndex\" = seq(1, length(pred.label)), \"Prediction\" = pred.label),  \n",
    "          \"RegressionPredictLabel.csv\", row.names = F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLEASE DO NOT ALTER THIS CODE BLOCK\n",
    "## Please skip (don't run) this if you are a student\n",
    "## For teaching team use only\n",
    "RMSE.fin <- rmse(pred.label, label$Label)\n",
    "cat(paste(\"RMSE is\", RMSE.fin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E-lggSuURze1"
   },
   "source": [
    "<h1>Part 2: Classification (50 Marks)</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, you are going to work with \"Census Income Dataset\" which was originally donated by Ronny Kohavi and Barry Becker to UCI (University of California, Irvine) in 1996. This is a trimmed dataset used for machine learning students to study classification. \n",
    "\n",
    "This dataset has collected over 40,000 records (we excluded some data in our version) regarding personal yearly income with 12 attributes (predictors). The attributes comprise many aspects of a person that may contribute to the yearly income. You can use summary() function to obtain the attributes information. Your prediction task is to determine whether a person makes over 50K a year.\n",
    "\n",
    "We have splitted the dataset into a trainning and a testing set. There are 27245 records in the training set while 13631 records in the testing set. Besides the 12 predictors, there is one more column named Salary indicating whether a person's yearly income is over 50K. The label information is a seperated file for the testing set and will be used by us to asess your performance later. Note the label TRUE means an individual's yearly salary exceeds 50K while FALSE means an individual's yearly salary is under 50K.\n",
    "\n",
    "$\\textbf{Note:}$ If not explicitly mentioned, libraries are not allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from students' side\n",
    "remove(list = ls())\n",
    "train <- read.csv(\"ClassTrain.csv\")\n",
    "test  <- read.csv(\"ClassTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLEASE DO NOT ALTER THIS CODE BLOCK\n",
    "# Please skip (don't run) this if you are a student\n",
    "# Read in the data from marking tutors' side (ensure no cheating!)\n",
    "remove(list = ls())\n",
    "train <- read.csv(\"../data/ClassTrain.csv\")\n",
    "test  <- read.csv(\"../data/ClassTest.csv\")\n",
    "label <- read.csv(\"../data/ClassTestLabel.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0epC4XmxOWJe"
   },
   "source": [
    "<h2> Question 1 (10 Marks) </h2>\n",
    "\n",
    "Fit a $\\textbf{Generalized Linear Model (Logistic Regression)}$ to predict level of income (salary) $\\left(\\;\\geq 50\\;\\text{K, or } <50\\;\\text{K}\\;\\right)$ using the ``train`` dataset. Using the results of fitting this model, which predictors do you think are possibly associated with the level of Salary (use ``0.05`` significant level), and why? Which ``three variables`` appear to be the strongest predictors of salary, and why? \n",
    "\n",
    "Furthermore, you can see that you have much more predictors in this part than in the ``linear model`` from Part 1 $\\Rightarrow$ manually checking information is counterproductive. Thus, please write a function to automate these processes $\\textbf{(1)}$ selecting important feature against 0.05 threshold and $\\textbf{(2)}$ Selecting three most important features.\n",
    "\n",
    "$\\textbf{Note}$: You don't have to worry about categorical variables here since R can deal with this automatically, focus your efforts on interpretation. Additionally, when explaining why features are strongly associated with the target, please refrain from giving one or two sentences answers, these answers are not descriptive and will result in a deduction of marks. Finally, please name the model here ``glm.fit`` and have the parameter in the model set to ``family = binomial``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Ybm3VKDOWJe"
   },
   "source": [
    "$\\textbf{YOUR ANSWER HERE}$  \n",
    "After building a generalized linear model (logistic regression), we can use a summary function to see the result of this model.\n",
    "###### Selecting important feature\n",
    "We find that Age, FinalWeight,WorkClassLocal-gov, WorkClassPrivate, WorkClassSelf-emp-inc, WorkClassSelf-emp-not-inc, Education7th-8th, EducationAssoc-acdm,EducationAssoc-voc, EducationBachelors,EducationDoctorate, EducationHS-grad, EducationMasters, EducationProf-school, EducationSome-college, MaritalStatus, Married-civ-spouse,  WorkClassState-gov, MaritalStatusNever-married, OccupationExec-managerial, OccupationFarming-fishing,  OccupationHandlers-cleaners, OccupationMachine-op-inspct, OccupationOther-service, OccupationProf-specialty, OccupationProtective-serv, OccupationSales, OccupationTech-support,RelationshipNot-in-family, RelationshipOwn-child, RelationshipWife, RaceAsian-Pac-Islander, RaceWhite, CapitalGain, CapitalLoss, WorkClass, GenderMale, and HoursWork are possibly associated with the level of Salary.  \n",
    "From the summary result, the significant level of these values are smaller than 0.05. So we can conclude that these predictors are possibly associated with the level of Salary. \n",
    "###### Selecting three most important features\n",
    "In order to choose the three strongest variables predictors of salary, we need to find the parameters with the smallest values of significance. (*** in the coefficients of the summary result). We would focus on the numeric values which consist of more information.  \n",
    "So, we have Age, CapitalGain, CapitalLoss, FinalWeight, and HoursWork.   \n",
    "Then, we need to focus on the raw data to have a general view of these parameters. Unfortunately, CapitalGain and CapitalLoss column contains many 0 values, which is useless to predict. So, we need to discard them.  \n",
    "In the end, we find out three variables appear to be the strongest predictors of salary.   \n",
    "They are Age, FinalWeight and HoursWork.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = Salary ~ ., family = binomial, data = train)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-5.1013  -0.5296  -0.1926   0.0276   3.4349  \n",
       "\n",
       "Coefficients:\n",
       "                                     Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)                        -7.614e+00  4.525e-01 -16.826  < 2e-16 ***\n",
       "Age                                 2.626e-02  1.779e-03  14.762  < 2e-16 ***\n",
       "WorkClassLocal-gov                 -7.214e-01  1.168e-01  -6.179 6.46e-10 ***\n",
       "WorkClassPrivate                   -4.734e-01  9.693e-02  -4.884 1.04e-06 ***\n",
       "WorkClassSelf-emp-inc              -2.974e-01  1.283e-01  -2.317 0.020506 *  \n",
       "WorkClassSelf-emp-not-inc          -9.994e-01  1.139e-01  -8.772  < 2e-16 ***\n",
       "WorkClassState-gov                 -7.757e-01  1.294e-01  -5.996 2.03e-09 ***\n",
       "FinalWeight                         7.896e-07  1.822e-07   4.334 1.46e-05 ***\n",
       "Education11th                       6.909e-02  2.201e-01   0.314 0.753589    \n",
       "Education12th                       5.005e-01  2.940e-01   1.702 0.088676 .  \n",
       "Education7th-8th                   -6.213e-01  2.592e-01  -2.397 0.016530 *  \n",
       "Education9th                       -2.472e-01  2.856e-01  -0.865 0.386877    \n",
       "EducationAssoc-acdm                 1.302e+00  1.843e-01   7.066 1.60e-12 ***\n",
       "EducationAssoc-voc                  1.263e+00  1.772e-01   7.127 1.02e-12 ***\n",
       "EducationBachelors                  1.931e+00  1.647e-01  11.724  < 2e-16 ***\n",
       "EducationDoctorate                  3.076e+00  2.380e-01  12.926  < 2e-16 ***\n",
       "EducationHS-grad                    7.790e-01  1.598e-01   4.874 1.09e-06 ***\n",
       "EducationMasters                    2.319e+00  1.767e-01  13.126  < 2e-16 ***\n",
       "EducationProf-school                2.874e+00  2.145e-01  13.396  < 2e-16 ***\n",
       "EducationSome-college               1.108e+00  1.622e-01   6.832 8.36e-12 ***\n",
       "MaritalStatusMarried-civ-spouse     2.345e+00  3.050e-01   7.687 1.51e-14 ***\n",
       "MaritalStatusMarried-spouse-absent -3.345e-02  2.697e-01  -0.124 0.901286    \n",
       "MaritalStatusNever-married         -4.513e-01  9.187e-02  -4.912 9.01e-07 ***\n",
       "MaritalStatusSeparated             -9.621e-02  1.733e-01  -0.555 0.578829    \n",
       "MaritalStatusWidowed                1.484e-01  1.656e-01   0.896 0.370163    \n",
       "OccupationCraft-repair              5.906e-02  8.379e-02   0.705 0.480884    \n",
       "OccupationExec-managerial           7.693e-01  8.089e-02   9.511  < 2e-16 ***\n",
       "OccupationFarming-fishing          -9.919e-01  1.457e-01  -6.805 1.01e-11 ***\n",
       "OccupationHandlers-cleaners        -7.641e-01  1.529e-01  -4.999 5.77e-07 ***\n",
       "OccupationMachine-op-inspct        -2.794e-01  1.073e-01  -2.605 0.009191 ** \n",
       "OccupationOther-service            -8.967e-01  1.300e-01  -6.900 5.22e-12 ***\n",
       "OccupationProf-specialty            4.654e-01  8.613e-02   5.403 6.54e-08 ***\n",
       "OccupationProtective-serv           6.229e-01  1.302e-01   4.784 1.72e-06 ***\n",
       "OccupationSales                     2.770e-01  8.625e-02   3.211 0.001322 ** \n",
       "OccupationTech-support              6.359e-01  1.159e-01   5.488 4.07e-08 ***\n",
       "OccupationTransport-moving         -1.027e-01  1.032e-01  -0.995 0.319541    \n",
       "RelationshipNot-in-family           6.652e-01  3.021e-01   2.202 0.027683 *  \n",
       "RelationshipOther-relative         -4.067e-01  2.918e-01  -1.394 0.163395    \n",
       "RelationshipOwn-child              -6.044e-01  2.943e-01  -2.054 0.039994 *  \n",
       "RelationshipUnmarried               5.707e-01  3.174e-01   1.798 0.072185 .  \n",
       "RelationshipWife                    1.332e+00  1.103e-01  12.071  < 2e-16 ***\n",
       "RaceAsian-Pac-Islander              9.879e-01  2.997e-01   3.296 0.000979 ***\n",
       "RaceBlack                           3.929e-01  2.427e-01   1.619 0.105400    \n",
       "RaceOther                           1.524e-01  4.397e-01   0.347 0.728862    \n",
       "RaceWhite                           5.396e-01  2.305e-01   2.340 0.019266 *  \n",
       "GenderMale                          8.679e-01  8.403e-02  10.328  < 2e-16 ***\n",
       "CapitalGain                         3.191e-04  1.107e-05  28.830  < 2e-16 ***\n",
       "CapitalLoss                         6.503e-04  3.999e-05  16.264  < 2e-16 ***\n",
       "HoursWork                           2.965e-02  1.774e-03  16.714  < 2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 31005  on 27244  degrees of freedom\n",
       "Residual deviance: 17976  on 27196  degrees of freedom\n",
       "AIC: 18074\n",
       "\n",
       "Number of Fisher Scoring iterations: 7\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build your model, keep family = binomial, ignore the warnings, they are benign\n",
    "glm.fit <- glm(Salary ~ ., data=train, family=binomial)\n",
    "summary(glm.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kEUu5eFpOWJi"
   },
   "source": [
    "<h2> Question 2 (10 Marks) </h2>\n",
    "\n",
    "Firstly, please use the model created in the previous question to predict for the labels of the $\\textbf{train}$ data. Consequently, our objective is to compare this ``predict.label`` with the ``truth.label`` from the $\\textbf{test}$ data. However, as we don't know the $\\textbf{test}$ label, we have to estimate model performance using $\\textbf{train}$ data at this moment.\n",
    "\n",
    "Secondly, since our objective is to estimate the performance of this model in making correct predictions; thus, this question also asks you to explore different [performance metrics](https://en.wikipedia.org/wiki/Precision_and_recall) for classification models. The metrics we will use are $\\textbf{Accuracy, Precision, Recall, and F1 Score}$, please create a function to calculate these value and print them out properly using the given structure.\n",
    "\n",
    "Additionally, please also discuss the results of these values in the context of your model.\n",
    "\n",
    "$\\textbf{Note}$: This asks for your descriptions, please refrain from using one or two lines to describe/discuss the effect. Keep answers to be 4 decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply your previous model to perform prediction, keep type = \"response\"\n",
    "# Don't worry if you receive some warnings, they are benign\n",
    "predict.label <- predict(glm.fit, train)\n",
    "# Truth label from train data\n",
    "truth.label <- train$Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model statistics function\n",
    "mod.stat <- function(predict.label, truth.label){\n",
    "    # instantiate the variables\n",
    "    accuracy <- NULL\n",
    "    precision <- NULL\n",
    "    recall <- NULL\n",
    "    F1 <- NULL\n",
    "    \n",
    "    tp <- 0\n",
    "    fp <- 0\n",
    "    fn <- 0 \n",
    "    tn <- 0\n",
    "    ##############################\n",
    "    #Your calculatation here\n",
    "    for (i in seq(1, length(truth.label))){\n",
    "    # Change the boolean to character in truth.label\n",
    "    if (truth.label[i] == \"TRUE\"){\n",
    "        truth.label[i] = \"1\"\n",
    "    }   \n",
    "    if (truth.label[i] == \"FALSE\"){\n",
    "        truth.label[i] = \"0\"\n",
    "    }   \n",
    "    # Change the numeric to character in predict.label\n",
    "    if (predict.label[i] >=0.5){\n",
    "        predict.label[i] = \"1\"\n",
    "    }\n",
    "    if (predict.label[i] <0.5){\n",
    "        predict.label[i] = \"0\"\n",
    "    }  \n",
    "    \n",
    "    # If the answer is right\n",
    "    if (predict.label[i] == truth.label[i]){\n",
    "        # True positive\n",
    "        if (predict.label[i] == \"1\"){\n",
    "            tp = tp + 1\n",
    "        }\n",
    "        # True negative\n",
    "        if (predict.label[i] == \"0\"){\n",
    "            tn = tn + 1\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # If the answer is wrong\n",
    "    if (predict.label[i] != truth.label[i]){\n",
    "        # False positive\n",
    "        if (predict.label[i] == \"1\"){\n",
    "            fp = fp + 1\n",
    "        }\n",
    "        # False negative\n",
    "        if (predict.label[i] == \"0\"){\n",
    "            fn = fn + 1\n",
    "        }\n",
    "    }\n",
    "}\n",
    "     # Keep answers to be 4 decimal places\n",
    "     accuracy = round( ( tp + tn ) / (tp + tn + fp + fn) , 4 )\n",
    "     precision = round( tp  / (tp + fp) , 4 )\n",
    "     recall = round( tp  / (tp + fn) , 4 )\n",
    "     F1 = round( 2*tp / (2*tp + fp +fn) , 4 )\n",
    "    ##############################\n",
    "    \n",
    "    # Return a list of value\n",
    "    return(list(\"accuracy\" = accuracy, \"precision\" = precision, \"recall\" = recall, \"fscore\" = F1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$accuracy</dt>\n",
       "\t\t<dd>0.8386</dd>\n",
       "\t<dt>$precision</dt>\n",
       "\t\t<dd>0.8052</dd>\n",
       "\t<dt>$recall</dt>\n",
       "\t\t<dd>0.4879</dd>\n",
       "\t<dt>$fscore</dt>\n",
       "\t\t<dd>0.6076</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$accuracy] 0.8386\n",
       "\\item[\\$precision] 0.8052\n",
       "\\item[\\$recall] 0.4879\n",
       "\\item[\\$fscore] 0.6076\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$accuracy\n",
       ":   0.8386\n",
       "$precision\n",
       ":   0.8052\n",
       "$recall\n",
       ":   0.4879\n",
       "$fscore\n",
       ":   0.6076\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$accuracy\n",
       "[1] 0.8386\n",
       "\n",
       "$precision\n",
       "[1] 0.8052\n",
       "\n",
       "$recall\n",
       "[1] 0.4879\n",
       "\n",
       "$fscore\n",
       "[1] 0.6076\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the function to get statistics, provide description/discussion after this\n",
    "mod.stat(predict.label, truth.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{YOUR ANSWER HERE}$  \n",
    "From the results of my model, we find that the accuracy and precision are pretty high, but the recall is lower than 50%. \n",
    "This means this model is poor in figuring out True positive and good at True negative.   \n",
    "To be specific, it misclassifies many true values to false. On the other hand, it performs well at recognizing false value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C6XyKtwfOWJj"
   },
   "source": [
    "<h2> Question 3 (5 Marks) </h2>\n",
    "\n",
    "Use the stepwise selection procedure with the $\\textbf{BIC}$ penalty to prune out potentially unimportant variables. Checking the performance of your model using the created ``mod.stat()`` function, please give your discussion as how this model is compared with the ``glm.fit``(you can run the ``mod.stat()`` function for this as well if you want to).\n",
    "\n",
    "$\\textbf{Note}$: please don't change the default direction ``both`` in the step function, this is so that we can check your work easily. Additionally, please name this model ``sw.fit``. Don't worry about the warnings, they are benign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Ybm3VKDOWJe"
   },
   "source": [
    "$\\textbf{YOUR ANSWER HERE}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = Salary ~ Age + WorkClass + FinalWeight + Education + \n",
       "    MaritalStatus + Occupation + Relationship + Gender + CapitalGain + \n",
       "    CapitalLoss + HoursWork, family = binomial, data = train)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-5.0961  -0.5291  -0.1936   0.0279   3.4393  \n",
       "\n",
       "Coefficients:\n",
       "                                     Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)                        -7.130e+00  3.929e-01 -18.146  < 2e-16 ***\n",
       "Age                                 2.644e-02  1.778e-03  14.869  < 2e-16 ***\n",
       "WorkClassLocal-gov                 -7.159e-01  1.163e-01  -6.154 7.54e-10 ***\n",
       "WorkClassPrivate                   -4.588e-01  9.626e-02  -4.766 1.88e-06 ***\n",
       "WorkClassSelf-emp-inc              -2.776e-01  1.278e-01  -2.173  0.02977 *  \n",
       "WorkClassSelf-emp-not-inc          -9.857e-01  1.133e-01  -8.703  < 2e-16 ***\n",
       "WorkClassState-gov                 -7.653e-01  1.290e-01  -5.930 3.02e-09 ***\n",
       "FinalWeight                         7.496e-07  1.800e-07   4.164 3.13e-05 ***\n",
       "Education11th                       7.190e-02  2.201e-01   0.327  0.74395    \n",
       "Education12th                       5.065e-01  2.939e-01   1.724  0.08479 .  \n",
       "Education7th-8th                   -6.220e-01  2.593e-01  -2.399  0.01643 *  \n",
       "Education9th                       -2.417e-01  2.851e-01  -0.848  0.39663    \n",
       "EducationAssoc-acdm                 1.323e+00  1.841e-01   7.187 6.60e-13 ***\n",
       "EducationAssoc-voc                  1.277e+00  1.770e-01   7.215 5.38e-13 ***\n",
       "EducationBachelors                  1.947e+00  1.645e-01  11.838  < 2e-16 ***\n",
       "EducationDoctorate                  3.089e+00  2.377e-01  12.998  < 2e-16 ***\n",
       "EducationHS-grad                    7.881e-01  1.596e-01   4.937 7.95e-07 ***\n",
       "EducationMasters                    2.337e+00  1.765e-01  13.239  < 2e-16 ***\n",
       "EducationProf-school                2.894e+00  2.145e-01  13.495  < 2e-16 ***\n",
       "EducationSome-college               1.117e+00  1.621e-01   6.893 5.47e-12 ***\n",
       "MaritalStatusMarried-civ-spouse     2.357e+00  3.045e-01   7.743 9.75e-15 ***\n",
       "MaritalStatusMarried-spouse-absent -3.049e-02  2.690e-01  -0.113  0.90977    \n",
       "MaritalStatusNever-married         -4.482e-01  9.172e-02  -4.886 1.03e-06 ***\n",
       "MaritalStatusSeparated             -1.101e-01  1.728e-01  -0.637  0.52405    \n",
       "MaritalStatusWidowed                1.497e-01  1.655e-01   0.904  0.36583    \n",
       "OccupationCraft-repair              6.350e-02  8.372e-02   0.759  0.44812    \n",
       "OccupationExec-managerial           7.726e-01  8.083e-02   9.558  < 2e-16 ***\n",
       "OccupationFarming-fishing          -9.869e-01  1.456e-01  -6.779 1.21e-11 ***\n",
       "OccupationHandlers-cleaners        -7.678e-01  1.528e-01  -5.026 5.02e-07 ***\n",
       "OccupationMachine-op-inspct        -2.857e-01  1.072e-01  -2.665  0.00770 ** \n",
       "OccupationOther-service            -9.059e-01  1.298e-01  -6.981 2.92e-12 ***\n",
       "OccupationProf-specialty            4.656e-01  8.599e-02   5.414 6.15e-08 ***\n",
       "OccupationProtective-serv           6.192e-01  1.301e-01   4.760 1.94e-06 ***\n",
       "OccupationSales                     2.797e-01  8.618e-02   3.246  0.00117 ** \n",
       "OccupationTech-support              6.444e-01  1.157e-01   5.568 2.57e-08 ***\n",
       "OccupationTransport-moving         -1.082e-01  1.031e-01  -1.050  0.29391    \n",
       "RelationshipNot-in-family           6.761e-01  3.016e-01   2.242  0.02499 *  \n",
       "RelationshipOther-relative         -4.031e-01  2.920e-01  -1.381  0.16742    \n",
       "RelationshipOwn-child              -5.877e-01  2.935e-01  -2.002  0.04525 *  \n",
       "RelationshipUnmarried               5.744e-01  3.168e-01   1.813  0.06984 .  \n",
       "RelationshipWife                    1.332e+00  1.103e-01  12.076  < 2e-16 ***\n",
       "GenderMale                          8.747e-01  8.401e-02  10.412  < 2e-16 ***\n",
       "CapitalGain                         3.184e-04  1.106e-05  28.784  < 2e-16 ***\n",
       "CapitalLoss                         6.509e-04  3.998e-05  16.281  < 2e-16 ***\n",
       "HoursWork                           2.968e-02  1.774e-03  16.735  < 2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 31005  on 27244  degrees of freedom\n",
       "Residual deviance: 17992  on 27200  degrees of freedom\n",
       "AIC: 18082\n",
       "\n",
       "Number of Fisher Scoring iterations: 7\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setting to suppress warnings\n",
    "options(warn=-1)\n",
    "# Fit a stepwise model\n",
    "sw.fit <- step(glm.fit, trace=0, k = log(length(truth.label)), direction=\"both\")\n",
    "# Setting to suppress warnings\n",
    "options(warn=0)\n",
    "# Getting the summary to understand the result\n",
    "summary(sw.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$accuracy</dt>\n",
       "\t\t<dd>0.8387</dd>\n",
       "\t<dt>$precision</dt>\n",
       "\t\t<dd>0.8062</dd>\n",
       "\t<dt>$recall</dt>\n",
       "\t\t<dd>0.4876</dd>\n",
       "\t<dt>$fscore</dt>\n",
       "\t\t<dd>0.6077</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$accuracy] 0.8387\n",
       "\\item[\\$precision] 0.8062\n",
       "\\item[\\$recall] 0.4876\n",
       "\\item[\\$fscore] 0.6077\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$accuracy\n",
       ":   0.8387\n",
       "$precision\n",
       ":   0.8062\n",
       "$recall\n",
       ":   0.4876\n",
       "$fscore\n",
       ":   0.6077\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$accuracy\n",
       "[1] 0.8387\n",
       "\n",
       "$precision\n",
       "[1] 0.8062\n",
       "\n",
       "$recall\n",
       "[1] 0.4876\n",
       "\n",
       "$fscore\n",
       "[1] 0.6077\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Making prediction using train data and view the statistics\n",
    "predict.label.sw <- predict(sw.fit, train)\n",
    "# Only run the below if you have labels, in your submission, this must be UNCOMMENTED\n",
    "mod.stat(predict.label.sw, truth.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROVIDE DISCUSSION HERE  \n",
    "\n",
    "In this model, it has removed many variables, such as Race, so the resulting model is quite a bit simpler.  \n",
    "But when we use mod.stat function to check the performance metrics for classification models, we find that the improvement is very limited. To be specific, the accuracy and precision increase by 0.0001 and 0.001 respectively.  \n",
    "In summary, using the stepwise selection procedure with the BIC penalty is useless in this question, it improves the model performs slightly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Question 4 (Libraries are allowed) (25 Marks) </h2>\n",
    "\n",
    "Similar to the first part, to simulate for a realistic modelling process, this question will be in the form of a competition among students to find out who has the best model.\n",
    "\n",
    "Thus, You will be graded by the performance of your model compared to your classmates', the better your model, the higher your score. Additionally, you need to write a short paragraph describing/documenting your thought process in this model building process ``(300 words)``. Note that this is to explain to us why you build your current model so that we can verify that you understand the model you build and not just copy from other people.\n",
    "\n",
    "$\\textbf{Note}$ Please make sure that we can install the libraries that you use in this part, the code structure can be:\n",
    "\n",
    "``install.packages(\"some package\", repos='http://cran.us.r-project.org')``\n",
    "\n",
    "``library(\"some package\")``\n",
    "\n",
    "Remember that if we cannot run your code, we will have to give you a deduction, our suggestion is for you to use the standard ``R version 3.6.1``\n",
    "\n",
    "You also need to name your final model ``fin.mod`` so we can run a check to find out your performance. A good test for your understanding would be to set the previous $\\textbf{BIC model}$ to be the final model to check if your code works perfectly.\n",
    "\n",
    "\n",
    "$20$ Marks for the model performance in the competition\n",
    "\n",
    "$5$ Marks for logically writing down the thought process in building the final model\n",
    "\n",
    "This is the [link](https://www.kaggle.com/t/1bdebc96607742dbaf47ab36cd3ae421) to the competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{YOUR ANSWER HERE}$  \n",
    "I write a short paragraph describing/documenting my thought process in this model building process under each code block. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for ( a in seq(0, 10, by = 0.1)){\n",
    "#train <- read.csv(\"ClassTrain.csv\")\n",
    "#train$WorkClass[which(train$WorkClass == \"Federal-gov\" )] = a\n",
    "#train$WorkClass[which(train$WorkClass == \"Private\" )] = 0\n",
    "#train$WorkClass[which(train$WorkClass == \"Self-emp-inc\" )] = 0\n",
    "#train$WorkClass[which(train$WorkClass == \"Self-emp-not-inc\" )] = 0\n",
    "#train$WorkClass[which(train$WorkClass == \"State-gov\" )] = 0\n",
    "#train$WorkClass[which(train$WorkClass == \"Local-gov\" )] = 0\n",
    "#train$WorkClass <- as.numeric(train$WorkClass)\n",
    "\n",
    "#glm.fit <- glm(Salary ~ ., data=train, family=binomial)\n",
    "#predict <- predict(glm.fit, train)\n",
    "#mod.stat(predict, truth.label)\n",
    "#}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find many characters attributes in the data, which is not convenient for us to build a model. As a result, we need to translate these character values into numeric values.  \n",
    "In this part, we use specific numeric values to present each character's values.  \n",
    "Here is a problem, which number is the best one to present a character value?   \n",
    "To solve this, I create a for loop (you can see it in comment) from 0 to 10, step is 0.1, to try the different number for each variable, and create a multiple regression model using all the data.  \n",
    "Then, we will call the mod.stat function to calculate the performance metrics. We will use the specific number, to get the lowest accuracy, precision, and recall to present that character.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use specific numeric values to present WorkClass\n",
    "train$WorkClass[which(train$WorkClass == \"Federal-gov\" )] = 0.01\n",
    "train$WorkClass[which(train$WorkClass == \"Private\" )] = 0.5\n",
    "train$WorkClass[which(train$WorkClass == \"Self-emp-inc\" )] = 2.6\n",
    "train$WorkClass[which(train$WorkClass == \"Self-emp-not-inc\" )] = 4.4\n",
    "train$WorkClass[which(train$WorkClass == \"State-gov\" )] = 3.8\n",
    "train$WorkClass[which(train$WorkClass == \"Local-gov\" )] = 6\n",
    "train$WorkClass <- as.numeric(train$WorkClass)\n",
    "# Use specific numeric values to present Race\n",
    "train$Race[which(train$Race == \"Amer-Indian-Eskimo\" )] = 1.2\n",
    "train$Race[which(train$Race == \"Asian-Pac-Islander\" )] = 5\n",
    "train$Race[which(train$Race == \"Black\" )] = 0.01\n",
    "train$Race[which(train$Race == \"Other\" )] = 0.01\n",
    "train$Race[which(train$Race == \"White\" )] = 5\n",
    "train$Race <- as.numeric(train$Race)\n",
    "# Use specific numeric values to present Gender\n",
    "train$Gender[which(train$Gender == \"Female\" )] = 1\n",
    "train$Gender[which(train$Gender == \"Male\" )] = 2\n",
    "train$Gender <- as.numeric(train$Gender)\n",
    "# Use specific numeric values to present MaritalStatus\n",
    "train$MaritalStatus[which(train$MaritalStatus == \"Divorced\" )] = 1\n",
    "train$MaritalStatus[which(train$MaritalStatus == \"Married-civ-spouse\" )] = 3\n",
    "train$MaritalStatus[which(train$MaritalStatus == \"Married-spouse-absent\" )] = 0.01\n",
    "train$MaritalStatus[which(train$MaritalStatus == \"Never-married\" )] = 0.01\n",
    "train$MaritalStatus[which(train$MaritalStatus == \"Separated\" )] = 0.01\n",
    "train$MaritalStatus[which(train$MaritalStatus == \"Widowed\" )] = 0.01\n",
    "train$MaritalStatus <- as.numeric(train$MaritalStatus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also choose a fancy model building method to create the model.      \n",
    "To be specific, we fit a full model with logs of all variables, and squares of all variables.  \n",
    "Next step, we apply the stepwise selection procedure with the BIC penalty to prune out potentially less significant variables and get the final model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$accuracy</dt>\n",
       "\t\t<dd>0.8432</dd>\n",
       "\t<dt>$precision</dt>\n",
       "\t\t<dd>0.8159</dd>\n",
       "\t<dt>$recall</dt>\n",
       "\t\t<dd>0.5009</dd>\n",
       "\t<dt>$fscore</dt>\n",
       "\t\t<dd>0.6207</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$accuracy] 0.8432\n",
       "\\item[\\$precision] 0.8159\n",
       "\\item[\\$recall] 0.5009\n",
       "\\item[\\$fscore] 0.6207\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$accuracy\n",
       ":   0.8432\n",
       "$precision\n",
       ":   0.8159\n",
       "$recall\n",
       ":   0.5009\n",
       "$fscore\n",
       ":   0.6207\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$accuracy\n",
       "[1] 0.8432\n",
       "\n",
       "$precision\n",
       "[1] 0.8159\n",
       "\n",
       "$recall\n",
       "[1] 0.5009\n",
       "\n",
       "$fscore\n",
       "[1] 0.6207\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(warn=-1)\n",
    "glm.fit <- glm(Salary ~ .+  log(WorkClass)+ log(Race)+ log(MaritalStatus)\n",
    "             +log(HoursWork) + log(Age) + log(FinalWeight)+ I(WorkClass^2) \n",
    "             + I(Race^2)+ I(MaritalStatus^2) + I(HoursWork^2)+ I(FinalWeight^2) \n",
    "             + I(Age^2), data=train, family=binomial)\n",
    "sw.fit <- step(glm.fit,trace=0, k = log(length(train[,1])), direction=\"both\")\n",
    "predict.label.sw <- predict(sw.fit, train)\n",
    "mod.stat(predict.label.sw, truth.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the BIC procedure, we get our final model.  \n",
    "We use this model to calculate the different performance metrics for classification models. We get 0.8432 of accuracy and 0.8159 of precision, which is better than the previous model in question 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(warn=-1)\n",
    "# Build your final model here, use additional coding block if you want to\n",
    "glm.fit <- glm(formula = Salary ~ Age + Education + FinalWeight + MaritalStatus + Occupation + \n",
    "    Relationship + Race + Gender + CapitalGain + CapitalLoss + \n",
    "    HoursWork + log(WorkClass) + log(Age) + log(HoursWork) +\n",
    "    log(FinalWeight), family = binomial, data = train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next part is about predict the test data.  \n",
    "In order to use my model to predict the level of salary, we need to do some preprocessing to the raw data.  \n",
    "After that, we can use my model to predict the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use specific numeric values to present WorkClass\n",
    "test$WorkClass[which(test$WorkClass == \"Federal-gov\" )] = 0.01\n",
    "test$WorkClass[which(test$WorkClass == \"Private\" )] = 0.5\n",
    "test$WorkClass[which(test$WorkClass == \"Self-emp-inc\" )] = 2.6\n",
    "test$WorkClass[which(test$WorkClass == \"Self-emp-not-inc\" )] = 4.4\n",
    "test$WorkClass[which(test$WorkClass == \"State-gov\" )] = 3.8\n",
    "test$WorkClass[which(test$WorkClass == \"Local-gov\" )] = 6\n",
    "test$WorkClass <- as.numeric(test$WorkClass)\n",
    "# Use specific numeric values to present Race\n",
    "test$Race[which(test$Race == \"Amer-Indian-Eskimo\" )] = 1.2\n",
    "test$Race[which(test$Race == \"Asian-Pac-Islander\" )] = 5\n",
    "test$Race[which(test$Race == \"Black\" )] = 0.01\n",
    "test$Race[which(test$Race == \"Other\" )] = 0.01\n",
    "test$Race[which(test$Race == \"White\" )] = 5\n",
    "test$Race <- as.numeric(test$Race)\n",
    "# Use specific numeric values to present Gender\n",
    "test$Gender[which(test$Gender == \"Female\" )] = 1\n",
    "test$Gender[which(test$Gender == \"Male\" )] = 2\n",
    "test$Gender <- as.numeric(test$Gender)\n",
    "# Use specific numeric values to present MaritalStatus\n",
    "test$MaritalStatus[which(test$MaritalStatus == \"Divorced\" )] = 1\n",
    "test$MaritalStatus[which(test$MaritalStatus == \"Married-civ-spouse\" )] = 3\n",
    "test$MaritalStatus[which(test$MaritalStatus == \"Married-spouse-absent\" )] = 0.01\n",
    "test$MaritalStatus[which(test$MaritalStatus == \"Never-married\" )] = 0.01\n",
    "test$MaritalStatus[which(test$MaritalStatus == \"Separated\" )] = 0.01\n",
    "test$MaritalStatus[which(test$MaritalStatus == \"Widowed\" )] = 0.01\n",
    "test$MaritalStatus <- as.numeric(test$MaritalStatus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we can get the result.  \n",
    "However, our result is numeric, we need to use some method to change the numeric format to logical values, which consist of \"TRUE\" or \"FALSE\" value. We set 0.5 as a threshold value, if the value larger than 0.5, we think they are TRUE. Otherwise, we regard them as FALSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the predict label for the TEST data\n",
    "pred.label <- predict(glm.fit, test)\n",
    "# Change the numeric number to logical\n",
    "for (i in seq(1:length(pred.label))){\n",
    "    if (pred.label[i] >=0.5){\n",
    "        pred.label[i] = \"TRUE\"\n",
    "    }\n",
    "    if (pred.label[i] <0.5){\n",
    "        pred.label[i] = \"FALSE\"\n",
    "    }  \n",
    "}\n",
    "pred.label <- as.logical(pred.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE DO NOT ALTER THIS CODE BLOCK\n",
    "# Use this csv file to commit to the leaderboard\n",
    "write.csv(data.frame(\"RowIndex\" = seq(1, length(pred.label)), \"Prediction\" = pred.label),  \n",
    "          \"ClassPredictLabel.csv\", row.names = F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in file(filename, \"r\", encoding = encoding): cannot open the connection\n",
     "output_type": "error",
     "traceback": [
      "Error in file(filename, \"r\", encoding = encoding): cannot open the connection\nTraceback:\n",
      "1. source(\"../data/modassess.r\")",
      "2. file(filename, \"r\", encoding = encoding)"
     ]
    }
   ],
   "source": [
    "## PLEASE DO NOT ALTER THIS CODE BLOCK\n",
    "## Please skip (don't run) this if you are a student\n",
    "## For teaching team use only\n",
    "source(\"../data/modassess.r\")\n",
    "model.perf <- mod.stat.test(pred.label,label$Label)\n",
    "print(model.perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Va7-A1UviCmz"
   },
   "source": [
    "<h1>References</h1>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment 1 Instructions and Contents.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
